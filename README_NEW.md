# Multi-Anime LoRA Training Toolkit

> **å¤šå‹•ç•« LoRA è¨“ç·´å·¥å…·åŒ…**

Professional toolkit for training character and style LoRAs from anime series.

Currently supports: **Yo-kai Watch (å¦–æ€ªæ‰‹éŒ¶)** | **Inazuma Eleven (é–ƒé›»åä¸€äºº)**

---

## ğŸ“š Quick Links (å¿«é€Ÿé€£çµ)

- [**Quick Start Guide**](docs/QUICKSTART.md) - Get started in 5 minutes
- [**Glossary**](GLOSSARY.md) - English-Chinese terminology reference (ä¸­è‹±è¡“èªå°ç…§)
- [**Documentation Index**](docs/INDEX.md) - Complete documentation navigation
- [**Yokai Watch Guide**](docs/anime-specific/yokai/) - Yo-kai Watch specific documentation
- [**Inazuma Eleven Guide**](docs/anime-specific/inazuma/) - Inazuma Eleven specific documentation

---

## âœ¨ Features

- **Multi-Series Support**: Organized structure for multiple anime series
- **Advanced Segmentation**: U2-Net, YOLO, Mask2Former for character extraction
- **Smart Clustering**: HDBSCAN + CLIP for automatic character grouping
- **Effect Detection**: Specialized tools for summon scenes, attacks, transformations
- **Taxonomy-Based**: Hierarchical classification (scenes, body types, effects)
- **Complete Pipelines**: Automated workflows from video â†’ training data
- **ControlNet Support**: Pose, depth, and multi-modal control image generation
- **Bilingual Docs**: English documentation with Chinese terminology reference

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Install all dependencies
pip install -r requirements/all.txt

# Or install by category
pip install -r requirements/core.txt
pip install -r requirements/segmentation.txt  # Optional: if using segmentation
pip install -r requirements/clustering.txt     # Optional: if using clustering
```

### 2. Choose Your Anime

#### Yo-kai Watch (å¦–æ€ªæ‰‹éŒ¶)
```bash
# Run full processing pipeline
python scripts/yokai/pipelines/yokai_pipeline_standard.py \
    --input /path/to/yokai/episodes \
    --output /path/to/training_data

# See complete guide
cat docs/anime-specific/yokai/YOKAI_COMPLETE_GUIDE.md
```

#### Inazuma Eleven (é–ƒé›»åä¸€äºº)
```bash
# Processing pipeline (coming soon)
python scripts/inazuma/pipelines/inazuma_pipeline.py \
    --input /path/to/inazuma/episodes \
    --output /path/to/training_data

# See guide
cat docs/anime-specific/inazuma/INAZUMA_GUIDE.md
```

---

## ğŸ“‚ Project Structure

```
multi-anime-lora-training/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ core/              # Shared utilities and models
â”‚   â”œâ”€â”€ yokai/             # Yo-kai Watch specific tools
â”‚   â”œâ”€â”€ inazuma/           # Inazuma Eleven specific tools
â”‚   â”œâ”€â”€ generic/           # Anime-agnostic processing tools
â”‚   â”œâ”€â”€ evaluation/        # Quality assessment
â”‚   â””â”€â”€ tests/             # Test suites
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ guides/            # General processing guides
â”‚   â”œâ”€â”€ anime-specific/    # Anime-specific documentation
â”‚   â””â”€â”€ reference/         # Technical reference
â”‚
â”œâ”€â”€ configs/               # Training configurations
â”œâ”€â”€ requirements/          # Dependency specifications
â””â”€â”€ GLOSSARY.md           # Terminology reference (ä¸­è‹±å°ç…§)
```

---

## ğŸ¯ What Can You Train?

### Character LoRAs
- Individual characters with consistent style
- Multiple characters from same series
- Character variants (transformations, outfits)

### Style LoRAs
- Body type styles (humanoid, beast, mecha, etc.)
- Attribute styles (fire, water, wind, etc.)
- Art styles (cute, cool, brave, etc.)

### Effect LoRAs
- Summon effects (magic circles, beams, portals)
- Attack effects (beams, auras, explosions)
- Transformation effects (shadowside, fusion, etc.)

### Background LoRAs
- Scene types (school, forest, yo-kai world, etc.)
- Time variations (day, night, festival, etc.)
- Environment types (indoor, outdoor, fantasy, etc.)

### ControlNet Datasets
- Character poses (humanoid and non-humanoid)
- Depth maps (optimized for anime)
- Line art and segmentation masks

---

## ğŸ“– Documentation

### Getting Started
- [Quick Start](docs/QUICKSTART.md) - 5-minute setup
- [Installation Guide](docs/guides/installation.md)
- [First Training](docs/guides/first_training.md)

### Core Concepts
- [Segmentation Guide](docs/guides/segmentation.md) - Character extraction
- [Clustering Guide](docs/guides/clustering.md) - Character grouping
- [Training Guide](docs/guides/training.md) - LoRA training basics

### Anime-Specific
- [Yo-kai Watch Complete Guide](docs/anime-specific/yokai/YOKAI_COMPLETE_GUIDE.md)
- [Yo-kai Watch Tools Reference](docs/anime-specific/yokai/YOKAI_TOOLS_REFERENCE.md)
- [Yo-kai Watch Schema](docs/anime-specific/yokai/YOKAI_SCHEMA.md)
- [Inazuma Eleven Guide](docs/anime-specific/inazuma/INAZUMA_GUIDE.md)

### Advanced Topics
- [Effect Detection & Organization](docs/guides/effects.md)
- [Scene Classification](docs/guides/scenes.md)
- [ControlNet Preparation](docs/guides/controlnet.md)
- [Multi-Concept LoRAs](docs/guides/multi_concept.md)

---

## ğŸ› ï¸ Tools Overview

### Yokai Watch Tools (å¦–æ€ªæ‰‹éŒ¶å·¥å…·)
- `yokai_summon_detector.py` - Detect summon scenes (å¬å–šå ´æ™¯æª¢æ¸¬)
- `yokai_style_classifier.py` - AI style classification (AI é¢¨æ ¼åˆ†é¡)
- `scene_type_classifier.py` - Hierarchical scene classification (å ´æ™¯åˆ†é¡)
- `special_effects_organizer.py` - Effect categorization (ç‰¹æ•ˆçµ„ç¹”)
- `advanced_pose_extractor.py` - Pose detection (å§¿æ…‹æå–)

### Generic Tools (é€šç”¨å·¥å…·)
- `layered_segmentation.py` - Character/background separation (åˆ†å±¤åˆ†å‰²)
- `character_clustering.py` - Automatic character grouping (è§’è‰²èšé¡)
- `universal_frame_extractor.py` - Video frame extraction (å½±æ ¼æå–)
- `audio_extractor.py` - Audio analysis and extraction (éŸ³è¨Šåˆ†æ)

### Evaluation Tools (è©•ä¼°å·¥å…·)
- `lora_validator.py` - Quality metrics (å“è³ªè©•ä¼°)
- `compare_models.py` - Model comparison (æ¨¡å‹æ¯”è¼ƒ)

---

## ğŸ’» Requirements

- **Python**: 3.10+
- **PyTorch**: 2.0+ with CUDA support
- **GPU**: NVIDIA GPU with 8GB+ VRAM (16GB+ recommended)
- **Storage**: 50GB+ free space for processing
- **RAM**: 16GB+ (32GB recommended)

---

## ğŸ“Š Project Status

| Component | Status | Notes |
|-----------|--------|-------|
| Core Infrastructure | âœ… Complete | Segmentation, clustering, pipelines |
| Yo-kai Watch Support | âœ… Complete | 16 specialized tools, full taxonomy |
| Inazuma Eleven Support | ğŸš§ In Progress | Basic structure, needs tools |
| Documentation | âœ… Complete | English docs + terminology |
| Test Suite | âœ… Complete | 4 consolidated test files |

---

## ğŸ¤ Contributing

This is a research project. For issues or suggestions, please check the documentation first.

---

## ğŸ“œ License

[Add your license here]

---

## ğŸ™ Credits

- **U2-Net**: Qin et al., Xueb in Qin, Zichen Zhang, Chenyang Huang, Masood Dehghan, Osmar R. Zaiane, Martin Jagersand
- **CLIP**: OpenAI
- **BLIP-2**: Salesforce Research
- **YOLO**: Ultralytics
- **HDBSCAN**: Leland McInnes

---

## ğŸ“§ Contact

[Add contact information]

---

**Version**: 2.0.0
**Last Updated**: 2025-10-30
**Project Reorganization**: Phase 1 Complete

---

## ğŸŒ Language / èªè¨€

This project uses English as the primary language for all documentation and code, with Chinese terminology provided in the [GLOSSARY.md](GLOSSARY.md) file.

æœ¬å°ˆæ¡ˆä½¿ç”¨è‹±æ–‡ä½œç‚ºæ‰€æœ‰æ–‡æª”å’Œç¨‹å¼ç¢¼çš„ä¸»è¦èªè¨€ï¼Œä¸­æ–‡è¡“èªå°ç…§è«‹åƒè€ƒ [GLOSSARY.md](GLOSSARY.md) æª”æ¡ˆã€‚
