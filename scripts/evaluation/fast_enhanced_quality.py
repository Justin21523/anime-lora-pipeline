#!/usr/bin/env python3
"""
Fast Enhanced Quality Assessment - Optimized Version
Uses batch processing and parallel computation for 3-5x speedup
"""

import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
from pathlib import Path
from typing import List, Dict
import logging
from tqdm import tqdm
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import partial

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FastAnimeQualityAssessor(nn.Module):
    """Fast quality assessment with batch processing"""

    def __init__(self, device='cuda', use_fp16=False):
        super().__init__()
        self.device = device
        self.use_fp16 = use_fp16

        # EfficientNet-B0 for speed
        self.backbone = models.efficientnet_b0(weights='DEFAULT')
        self.backbone.classifier = nn.Identity()

        # Simplified quality head
        self.quality_head = nn.Sequential(
            nn.Linear(1280, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

        self.backbone.to(device)
        self.quality_head.to(device)

        if use_fp16:
            self.backbone = self.backbone.half()
            self.quality_head = self.quality_head.half()

        self.eval()

    @torch.no_grad()
    def forward(self, images: torch.Tensor) -> torch.Tensor:
        if self.use_fp16:
            images = images.half()
        features = self.backbone(images)
        quality = self.quality_head(features).squeeze(-1)
        return quality


def calculate_fast_metrics(img_array: np.ndarray, alpha: np.ndarray = None) -> Dict:
    """
    Fast calculation of essential metrics
    Optimized for speed - only compute most important metrics
    """
    metrics = {}

    # Convert to grayscale once
    if len(img_array.shape) == 3:
        gray = np.mean(img_array, axis=2).astype(np.uint8)
    else:
        gray = img_array

    # 1. Sharpness (simplified - use std of gradients)
    gy = np.abs(np.diff(gray, axis=0))
    gx = np.abs(np.diff(gray, axis=1))
    sharpness = (np.std(gy) + np.std(gx)) / 100.0
    metrics['sharpness'] = float(np.clip(sharpness, 0, 1))

    # 2. Contrast (simple std)
    contrast = np.std(gray) / 80.0
    metrics['contrast'] = float(np.clip(contrast, 0, 1))

    # 3. Brightness
    metrics['brightness'] = float(np.mean(img_array) / 255.0)

    # 4. Saturation (only for color images)
    if len(img_array.shape) == 3:
        img_float = img_array.astype(np.float32) / 255.0
        max_val = np.max(img_float, axis=2)
        min_val = np.min(img_float, axis=2)
        with np.errstate(divide='ignore', invalid='ignore'):
            saturation = np.where(max_val > 0, (max_val - min_val) / max_val, 0)
        metrics['saturation'] = float(np.mean(saturation))
    else:
        metrics['saturation'] = 0.5

    # 5. Coverage (if alpha channel exists)
    if alpha is not None:
        metrics['coverage'] = float(np.sum(alpha > 10) / alpha.size)
    else:
        metrics['coverage'] = 1.0

    return metrics


def process_single_image_metrics(img_path: Path) -> Dict:
    """Process traditional metrics for single image (for parallel processing)"""
    try:
        img_pil = Image.open(img_path).convert('RGBA')
        img_array = np.array(img_pil)

        if img_array.shape[2] == 4:
            alpha = img_array[:, :, 3]
            rgb = img_array[:, :, :3]
        else:
            alpha = None
            rgb = img_array

        metrics = calculate_fast_metrics(rgb, alpha)
        metrics['image_path'] = str(img_path)
        metrics['image_name'] = img_path.name

        return metrics
    except Exception as e:
        logger.error(f"Error processing {img_path}: {e}")
        return None


class FastQualityPipeline:
    """Fast quality assessment pipeline with batch processing"""

    def __init__(self, device='cuda', use_fp16=True, batch_size=32):
        self.device = device
        self.batch_size = batch_size
        self.use_fp16 = use_fp16

        # Initialize model
        self.model = FastAnimeQualityAssessor(device=device, use_fp16=use_fp16)

        # Transform
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

        logger.info(f"Fast pipeline initialized (FP16={use_fp16}, batch={batch_size})")

    def assess_batch(
        self,
        image_paths: List[Path],
        output_path: Path,
        num_workers: int = 8
    ):
        """
        Fast batch assessment with parallel processing

        Args:
            image_paths: List of image paths
            output_path: Output JSON path
            num_workers: Number of parallel workers for traditional metrics
        """
        total = len(image_paths)
        logger.info(f"Processing {total} images...")

        # Step 1: Batch process deep learning quality scores
        logger.info("Step 1/2: Computing DL quality scores (GPU batch)...")
        dl_scores = self._batch_dl_inference(image_paths)

        # Step 2: Parallel process traditional metrics
        logger.info(f"Step 2/2: Computing traditional metrics ({num_workers} workers)...")
        traditional_metrics = self._parallel_traditional_metrics(
            image_paths, num_workers
        )

        # Combine results
        logger.info("Combining results...")
        results = []
        for i, img_path in enumerate(image_paths):
            if traditional_metrics[i] is None:
                continue

            result = traditional_metrics[i].copy()
            result['dl_quality_score'] = float(dl_scores[i])

            # Compute combined scores
            trad_quality = (
                result['sharpness'] * 0.25 +
                result['contrast'] * 0.20 +
                result['saturation'] * 0.15 +
                result['coverage'] * 0.40
            )
            result['traditional_quality_score'] = float(trad_quality)

            result['combined_quality_score'] = float(
                result['dl_quality_score'] * 0.6 +
                trad_quality * 0.4
            )

            result['enhanced_aesthetic_score'] = float(
                result['saturation'] * 0.35 +
                result['brightness'] * 0.25 +
                result['coverage'] * 0.25 +
                result['contrast'] * 0.15
            )

            results.append(result)

        # Save results
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w') as f:
            json.dump(results, f, indent=2)

        # Generate statistics
        self._generate_statistics(results, output_path.parent)

        logger.info(f"âœ… Assessment complete! Results: {output_path}")
        return results

    def _batch_dl_inference(self, image_paths: List[Path]) -> List[float]:
        """Batch inference for deep learning quality scores"""
        scores = []

        # Use autocast for FP16
        with torch.cuda.amp.autocast(enabled=self.use_fp16):
            for i in tqdm(range(0, len(image_paths), self.batch_size), desc="DL Inference"):
                batch_paths = image_paths[i:i + self.batch_size]

                # Load and transform batch
                batch_images = []
                for path in batch_paths:
                    try:
                        img = Image.open(path).convert('RGB')
                        img_tensor = self.transform(img)
                        batch_images.append(img_tensor)
                    except Exception as e:
                        logger.error(f"Failed to load {path}: {e}")
                        batch_images.append(torch.zeros(3, 224, 224))

                # Stack and infer
                batch_tensor = torch.stack(batch_images).to(self.device)
                batch_scores = self.model(batch_tensor).cpu().numpy()

                scores.extend(batch_scores.tolist())

        return scores

    def _parallel_traditional_metrics(
        self,
        image_paths: List[Path],
        num_workers: int
    ) -> List[Dict]:
        """Parallel computation of traditional metrics"""
        results = [None] * len(image_paths)

        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            future_to_idx = {
                executor.submit(process_single_image_metrics, path): i
                for i, path in enumerate(image_paths)
            }

            for future in tqdm(
                as_completed(future_to_idx),
                total=len(image_paths),
                desc="Traditional Metrics"
            ):
                idx = future_to_idx[future]
                results[idx] = future.result()

        return results

    def _generate_statistics(self, results: List[Dict], output_dir: Path):
        """Generate statistics"""
        if not results:
            return

        stats = {'total_images': len(results)}

        metrics = [
            'dl_quality_score',
            'traditional_quality_score',
            'combined_quality_score',
            'enhanced_aesthetic_score',
            'sharpness',
            'contrast',
            'saturation',
            'brightness',
            'coverage'
        ]

        for metric in metrics:
            values = [r[metric] for r in results if metric in r]
            if values:
                stats[f'{metric}_mean'] = float(np.mean(values))
                stats[f'{metric}_std'] = float(np.std(values))
                stats[f'{metric}_min'] = float(np.min(values))
                stats[f'{metric}_max'] = float(np.max(values))

                if 'quality' in metric or 'aesthetic' in metric:
                    stats[f'{metric}_high_count'] = len([v for v in values if v >= 0.6])

        stats_path = output_dir / 'fast_quality_statistics.json'
        with open(stats_path, 'w') as f:
            json.dump(stats, f, indent=2)

        logger.info(f"Statistics: {stats_path}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Fast Enhanced Quality Assessment")
    parser.add_argument('input_dir', type=Path, help='Input directory')
    parser.add_argument('--output-dir', type=Path, required=True, help='Output directory')
    parser.add_argument('--batch-size', type=int, default=32, help='Batch size for DL inference')
    parser.add_argument('--workers', type=int, default=8, help='Workers for traditional metrics')
    parser.add_argument('--device', type=str, default='cuda', help='Device')
    parser.add_argument('--no-fp16', action='store_true', help='Disable FP16')
    parser.add_argument('--pattern', type=str, default='*.png', help='File pattern')

    args = parser.parse_args()

    # Find images
    image_paths = list(Path(args.input_dir).rglob(args.pattern))
    logger.info(f"Found {len(image_paths)} images")

    # Initialize pipeline
    pipeline = FastQualityPipeline(
        device=args.device,
        use_fp16=not args.no_fp16,
        batch_size=args.batch_size
    )

    # Run assessment
    output_path = args.output_dir / 'fast_enhanced_quality.json'
    pipeline.assess_batch(
        image_paths=image_paths,
        output_path=output_path,
        num_workers=args.workers
    )


if __name__ == '__main__':
    main()
