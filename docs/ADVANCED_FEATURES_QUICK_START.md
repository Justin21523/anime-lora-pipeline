# Yokai Watch Advanced Features - Quick Start Guide

å¿«é€Ÿé–‹å§‹ä½¿ç”¨é€²éšŽè¨“ç·´åŠŸèƒ½çš„æŒ‡å—ã€‚

---

## âœ… å·²å¯¦ä½œåŠŸèƒ½ (6å€‹æ ¸å¿ƒå·¥å…·)

### 1. å¬å–šå ´æ™¯æª¢æ¸¬ ðŸŒŸ
**å·¥å…·**: `yokai_summon_scene_detector.py`

æª¢æ¸¬è¯éº—çš„å¦–æ€ªå¬å–šå‹•ç•«å ´æ™¯ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
python3 scripts/tools/yokai_summon_scene_detector.py \
    /path/to/episodes \
    --output-dir summon_scenes \
    --extract-mode key \
    --min-score 60.0
```

**åŠŸèƒ½**:
- è¦–è¦ºç‰¹æ•ˆæª¢æ¸¬ï¼ˆé–ƒå…‰ã€é­”æ³•é™£ã€å…‰æŸï¼‰
- éŸ³è¨Šåˆ†æžï¼ˆéŸ³æ•ˆã€èƒ½é‡ï¼‰
- å ´æ™¯è©•åˆ†ï¼ˆ0-100åˆ†ï¼‰
- ä¸‰ç¨®æå–æ¨¡å¼ï¼škeyï¼ˆé—œéµå¹€ï¼‰ã€allï¼ˆå…¨éƒ¨ï¼‰ã€sampleï¼ˆæŽ¡æ¨£ï¼‰

**è¼¸å‡º**:
```
summon_scenes/
â”œâ”€â”€ S1.01/
â”‚   â”œâ”€â”€ scene_001234/
â”‚   â”‚   â”œâ”€â”€ scene_001234_frame_001240.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â””â”€â”€ summon_scenes_metadata.json
```

---

### 2. å‹•ä½œåºåˆ—æå– ðŸŽ¬
**å·¥å…·**: `action_sequence_extractor.py`

æå–é€£çºŒå‹•ä½œåºåˆ—ç”¨æ–¼ AnimateDiff motion LoRA è¨“ç·´ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
python3 scripts/tools/action_sequence_extractor.py \
    /path/to/episodes \
    --output-dir action_sequences \
    --lengths 16 32 64 \
    --format animatediff
```

**åŠŸèƒ½**:
- å…‰æµé‹å‹•æª¢æ¸¬
- å ´æ™¯ä¸€è‡´æ€§åˆ†æž
- å‹•ä½œé¡žåž‹åˆ†é¡žï¼ˆç‰¹æ•ˆã€åŠ é€Ÿã€å‡ºå ´ç­‰ï¼‰
- æ”¯æŒ 8/16/32/64 å¹€åºåˆ—
- AnimateDiff æ ¼å¼è¼¸å‡º

**è¼¸å‡º**:
```
action_sequences/
â”œâ”€â”€ S1.01_seq001234_len16_entrance/
â”‚   â”œâ”€â”€ 0000.png
â”‚   â”œâ”€â”€ 0001.png
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ 0015.png
â”‚   â””â”€â”€ metadata.json
â””â”€â”€ sequences_metadata.json
```

---

### 3. ç‰¹æ•ˆçµ„ç¹”å™¨ âœ¨
**å·¥å…·**: `special_effects_organizer.py`

åˆ†é¡žå’Œçµ„ç¹”ç‰¹æ•ˆå ´æ™¯ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
python3 scripts/tools/special_effects_organizer.py \
    summon_scenes \
    --output-dir organized_effects \
    --separate-layers
```

**åŠŸèƒ½**:
- ç‰¹æ•ˆé¡žåž‹åˆ†é¡žï¼ˆå¬å–šã€æ”»æ“Šã€è®Šèº«ã€é­”æ³•é™£ç­‰ï¼‰
- ç‰¹æ•ˆ/è§’è‰²å±¤åˆ†é›¢
- ç´”ç‰¹æ•ˆæå–
- å¼·åº¦åˆ†æž

**è¼¸å‡º**:
```
organized_effects/
â”œâ”€â”€ by_type/
â”‚   â”œâ”€â”€ summon/
â”‚   â”œâ”€â”€ attack/
â”‚   â”œâ”€â”€ magic_circle/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ pure_effects/
â”‚   â”œâ”€â”€ summon/
â”‚   â””â”€â”€ ...
â””â”€â”€ combined/
```

---

### 4. é¢¨æ ¼åˆ†é¡žå™¨ ðŸŽ¨
**å·¥å…·**: `yokai_style_classifier.py`

ä½¿ç”¨ AI è‡ªå‹•åˆ†é¡žå¦–æ€ªé¢¨æ ¼å’Œå±¬æ€§ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
# è‡ªå‹•åˆ†é¡ž + äº’å‹•å¯©æ ¸
python3 scripts/tools/yokai_style_classifier.py \
    /path/to/character_clusters \
    --output-json yokai_taxonomy.json

# ç´”è‡ªå‹•ï¼ˆä¸äº’å‹•ï¼‰
python3 scripts/tools/yokai_style_classifier.py \
    /path/to/character_clusters \
    --output-json yokai_taxonomy.json \
    --no-interactive
```

**åŠŸèƒ½**:
- CLIP AI è‡ªå‹•åˆ†é¡ž
- å¤šç¶­åº¦åˆ†é¡žï¼š
  - å¤–è§€ï¼šanimal_cat, animal_dog, humanoid, ghost ç­‰
  - å±¬æ€§ï¼šfire, water, wind, thunder ç­‰
  - é¢¨æ ¼ï¼šcute, cool, brave, scary ç­‰
  - é«”åž‹ï¼šquadruped, bipedal, flying ç­‰
- äº’å‹•å¼å¯©æ ¸å’Œèª¿æ•´

**è¼¸å‡º**:
```json
{
  "clusters": [
    {
      "cluster_name": "cluster_000",
      "classifications": {
        "appearance": {"animal_cat": 0.85},
        "attribute": {"fire": 0.72},
        "style": {"cute": 0.91}
      }
    }
  ],
  "statistics": {...}
}
```

---

### 5. å¤šæ¦‚å¿µ LoRA æº–å‚™å™¨ ðŸŽ¯
**å·¥å…·**: `multi_concept_lora_preparer.py`

æº–å‚™é¢¨æ ¼çµ„åˆè¨“ç·´ï¼ˆå¦‚"æ‰€æœ‰è²“åž‹å¦–æ€ª"ï¼‰ã€‚

**ä½¿ç”¨æ–¹æ³•**:

é¦–å…ˆå‰µå»º groups å®šç¾©æ–‡ä»¶ `groups.json`:
```json
[
  {
    "name": "cat_type_yokai",
    "category": "appearance",
    "values": ["animal_cat"]
  },
  {
    "name": "cute_yokai",
    "category": "style",
    "values": ["cute"]
  },
  {
    "name": "fire_attribute",
    "category": "attribute",
    "values": ["fire"]
  }
]
```

ç„¶å¾Œé‹è¡Œï¼š
```bash
python3 scripts/tools/multi_concept_lora_preparer.py \
    /path/to/character_clusters \
    --taxonomy yokai_taxonomy.json \
    --output-dir multi_concept_training \
    --groups groups.json \
    --training-type concept
```

**åŠŸèƒ½**:
- æŒ‰é¢¨æ ¼/é¡žåž‹çµ„åˆå¤šå€‹è§’è‰²
- å±¤ç´šè§¸ç™¼è©žç³»çµ±ï¼ˆ"yokai, cat-type, char001"ï¼‰
- æ¨£æœ¬å¹³è¡¡
- è‡ªå‹•åƒæ•¸å„ªåŒ–

**è¼¸å‡º**:
```
multi_concept_training/
â”œâ”€â”€ cat_type_yokai/
â”‚   â”œâ”€â”€ 12_cat_type_yokai/
â”‚   â”‚   â”œâ”€â”€ cluster_000_image001.png
â”‚   â”‚   â”œâ”€â”€ cluster_000_image001.txt  # "yokai, cat-type, char000, ..."
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ validation/
â”‚   â””â”€â”€ configs/
â”‚       â””â”€â”€ cat_type_yokai_config.toml
â””â”€â”€ multi_concept_metadata.json
```

**è¨“ç·´**:
```bash
accelerate launch train_network.py \
    --config_file multi_concept_training/cat_type_yokai/configs/cat_type_yokai_config.toml
```

---

### 6. ControlNet å®Œæ•´ç®¡é“ ðŸŽ®
**å·¥å…·**: `controlnet_complete_pipeline.py`

ä¸€æ¬¡ç”Ÿæˆæ‰€æœ‰ ControlNet æŽ§åˆ¶åœ–ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
# ç”Ÿæˆæ‰€æœ‰é¡žåž‹
python3 scripts/tools/controlnet_complete_pipeline.py \
    /path/to/character_images \
    --output-dir controlnet_dataset

# åªç”Ÿæˆç‰¹å®šé¡žåž‹
python3 scripts/tools/controlnet_complete_pipeline.py \
    /path/to/character_images \
    --output-dir controlnet_dataset \
    --control-types canny depth openpose

# ä½¿ç”¨èƒŒæ™¯å±¤æ”¹å–„æ·±åº¦åœ–
python3 scripts/tools/controlnet_complete_pipeline.py \
    /path/to/character_images \
    --output-dir controlnet_dataset \
    --background-dir /path/to/backgrounds
```

**åŠŸèƒ½**:
- **Canny**: é‚Šç·£æª¢æ¸¬
- **Depth**: æ·±åº¦åœ–ç”Ÿæˆï¼ˆå‹•ç•«å„ªåŒ–ï¼‰
- **OpenPose**: å§¿æ…‹æª¢æ¸¬
- **Lineart**: ç·šç¨¿æå–
- **Segmentation**: åˆ†å‰²é®ç½©

**è¼¸å‡º**:
```
controlnet_dataset/
â”œâ”€â”€ source/           # åŽŸåœ–
â”‚   â”œâ”€â”€ image001.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ canny/           # Canny é‚Šç·£
â”‚   â”œâ”€â”€ image001.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ depth/           # æ·±åº¦åœ–
â”œâ”€â”€ openpose/        # å§¿æ…‹éª¨æž¶
â”œâ”€â”€ lineart/         # ç·šç¨¿
â”œâ”€â”€ segmentation/    # åˆ†å‰²é®ç½©
â”œâ”€â”€ captions/        # Caption æ–‡å­—
â””â”€â”€ controlnet_metadata.json
```

---

## ðŸ”„ å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

### å·¥ä½œæµç¨‹ 1: å¬å–šç‰¹æ•ˆ LoRA

```bash
# 1. æª¢æ¸¬å¬å–šå ´æ™¯
python3 scripts/tools/yokai_summon_scene_detector.py \
    /home/b0979/yokai_input_fast \
    --output-dir summon_scenes \
    --extract-mode sample

# 2. çµ„ç¹”ç‰¹æ•ˆ
python3 scripts/tools/special_effects_organizer.py \
    summon_scenes \
    --output-dir organized_effects \
    --separate-layers

# 3. ç”Ÿæˆ Captionsï¼ˆä½¿ç”¨ç¾æœ‰å·¥å…·ï¼‰
python3 scripts/tools/batch_generate_captions_yokai.py \
    organized_effects/by_type/summon

# 4. æº–å‚™è¨“ç·´ï¼ˆä½¿ç”¨ç¾æœ‰å·¥å…·ï¼‰
python3 scripts/tools/prepare_yokai_lora_training.py \
    organized_effects/by_type/summon \
    --output-dir training_data/summon_effects

# 5. è¨“ç·´
accelerate launch train_network.py \
    --config_file training_data/summon_effects/configs/char_000_config.toml
```

---

### å·¥ä½œæµç¨‹ 2: é¢¨æ ¼çµ„åˆ LoRAï¼ˆè²“åž‹å¦–æ€ªï¼‰

```bash
# 1. é¢¨æ ¼åˆ†é¡ž
python3 scripts/tools/yokai_style_classifier.py \
    character_clusters \
    --output-json yokai_taxonomy.json

# 2. å‰µå»º groups å®šç¾©
cat > cat_group.json <<EOF
[
  {
    "name": "cat_type_yokai",
    "category": "appearance",
    "values": ["animal_cat"]
  }
]
EOF

# 3. æº–å‚™å¤šæ¦‚å¿µè¨“ç·´
python3 scripts/tools/multi_concept_lora_preparer.py \
    character_clusters \
    --taxonomy yokai_taxonomy.json \
    --output-dir cat_lora_training \
    --groups cat_group.json \
    --training-type concept

# 4. è¨“ç·´
accelerate launch train_network.py \
    --config_file cat_lora_training/cat_type_yokai/configs/cat_type_yokai_config.toml
```

**çµæžœ**: ä¸€å€‹ LoRA å¯ä»¥ç”Ÿæˆæ‰€æœ‰è²“åž‹å¦–æ€ªï¼Œä½¿ç”¨è§¸ç™¼è©žï¼š
- "yokai, cat-type" - é€šç”¨è²“åž‹é¢¨æ ¼
- "yokai, cat-type, char000" - ç‰¹å®šå¦–æ€ª

---

### å·¥ä½œæµç¨‹ 3: AnimateDiff Motion LoRA

```bash
# 1. æå–å‹•ä½œåºåˆ—
python3 scripts/tools/action_sequence_extractor.py \
    /home/b0979/yokai_input_fast \
    --output-dir motion_sequences \
    --lengths 16 32 \
    --format animatediff

# 2. é¸æ“‡ç‰¹å®šå‹•ä½œé¡žåž‹ï¼ˆå¦‚å‡ºå ´å‹•ç•«ï¼‰
mkdir entrance_sequences
cp -r motion_sequences/*_entrance/ entrance_sequences/

# 3. è¨“ç·´ motion LoRAï¼ˆéœ€è¦ AnimateDiff è¨“ç·´è…³æœ¬ï¼‰
# ä½¿ç”¨ AnimateDiff è¨“ç·´æµç¨‹...
```

---

### å·¥ä½œæµç¨‹ 4: ControlNet è¨“ç·´æ•¸æ“š

```bash
# 1. ç”Ÿæˆæ‰€æœ‰æŽ§åˆ¶åœ–
python3 scripts/tools/controlnet_complete_pipeline.py \
    character_clusters/cluster_000 \
    --output-dir controlnet_data \
    --background-dir layered_frames/background

# 2. ä½¿ç”¨ ControlNet è¨“ç·´è…³æœ¬è¨“ç·´...
```

---

## ðŸ“ å¾…å®ŒæˆåŠŸèƒ½

ä»¥ä¸‹åŠŸèƒ½æœ‰å®Œæ•´è¦æ ¼ï¼ˆè¦‹ `ADVANCED_TOOLS_SPECIFICATION.md`ï¼‰ï¼Œä½†å°šæœªå¯¦ä½œï¼š

1. **scene_type_classifier.py** - å ´æ™¯é¡žåž‹åˆ†é¡žï¼ˆå®¤å…§/æˆ¶å¤–ç­‰ï¼‰
2. **interactive_style_organizer.py** - è¦–è¦ºåŒ–é¢¨æ ¼çµ„ç¹”ç•Œé¢
3. **advanced_pose_extractor.py** - é€²éšŽå§¿æ…‹æå–ï¼ˆå¦–æ€ªç‰¹æ®Šè™•ç†ï¼‰
4. **anime_depth_generator.py** - å‹•ç•«é¢¨æ ¼æ·±åº¦ç”Ÿæˆå™¨

å¦‚éœ€é€™äº›åŠŸèƒ½ï¼Œå¯ä»¥åƒè€ƒè¦æ ¼æ–‡æª”å¯¦ä½œï¼Œæˆ–è«‹æ±‚å”åŠ©ã€‚

---

## ðŸ’¡ ä½¿ç”¨å»ºè­°

### å„ªå…ˆä½¿ç”¨å ´æ™¯

1. **éœ€è¦ç‰¹æ•ˆ LoRA** â†’ ä½¿ç”¨å¬å–šå ´æ™¯æª¢æ¸¬ + ç‰¹æ•ˆçµ„ç¹”å™¨
2. **éœ€è¦é¢¨æ ¼ LoRA** â†’ ä½¿ç”¨é¢¨æ ¼åˆ†é¡žå™¨ + å¤šæ¦‚å¿µæº–å‚™å™¨
3. **éœ€è¦å‹•ç•«ç”Ÿæˆ** â†’ ä½¿ç”¨å‹•ä½œåºåˆ—æå–å™¨ + AnimateDiff
4. **éœ€è¦ç²¾ç¢ºæŽ§åˆ¶** â†’ ä½¿ç”¨ ControlNet ç®¡é“

### çµ„åˆä½¿ç”¨

å¤šå€‹ LoRA å¯ä»¥çµ„åˆä½¿ç”¨ï¼š
```
åŸºç¤Žæ¨¡åž‹
  + è§’è‰² LoRA (jibanyan)
  + ç‰¹æ•ˆ LoRA (summon_effects)
  + ControlNet Pose
  = ç‰¹å®šå§¿æ…‹çš„å‰èƒ–å–µå¬å–šå‹•ç•«
```

---

## ðŸ”§ ä¾è³´å®‰è£

```bash
# åŸºç¤Žä¾è³´ï¼ˆå·²æœ‰ï¼‰
conda activate blip2-env

# ControlNet ç›¸é—œï¼ˆéœ€è¦æ™‚å®‰è£ï¼‰
pip install controlnet_aux

# éŸ³è¨Šè™•ç†ï¼ˆéœ€è¦æ™‚å®‰è£ï¼‰
pip install librosa soundfile

# OpenPoseï¼ˆå¯é¸ï¼‰
# åƒè€ƒï¼šhttps://github.com/CMU-Perceptual-Computing-Lab/openpose
```

---

## ðŸ†˜ æ•…éšœæŽ’é™¤

### CUDA Out of Memory
```bash
# ä½¿ç”¨ CPU
--device cpu

# æˆ–æ¸›å°‘æ‰¹æ¬¡å¤§å°
--batch-size 4
```

### CLIP æ¨¡åž‹åŠ è¼‰å¤±æ•—
```bash
# ç¢ºèªç¶²çµ¡é€£æŽ¥ï¼Œæ¨¡åž‹æœƒè‡ªå‹•ä¸‹è¼‰
# æˆ–æ‰‹å‹•ä¸‹è¼‰åˆ° ~/.cache/huggingface/
```

### éŸ³è¨Šåˆ†æžå¤±æ•—
```bash
# å®‰è£ librosa
pip install librosa soundfile

# æˆ–ç¦ç”¨éŸ³è¨Š
--no-audio
```

---

**æœ€å¾Œæ›´æ–°**: 2025-10-30
**å·¥å…·ç‰ˆæœ¬**: v1.0
**ç‹€æ…‹**: 6/13 æ ¸å¿ƒåŠŸèƒ½å·²å¯¦ä½œ
