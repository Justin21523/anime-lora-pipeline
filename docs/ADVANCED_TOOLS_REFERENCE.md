# Advanced Tools Quick Reference

å¿«é€ŸæŸ¥é–±æ‰€æœ‰é€²éšå·¥å…·çš„åƒæ•¸å’Œç”¨æ³•ã€‚

**åˆ†é¡æ¨™æº–ç‰ˆæœ¬**: 2025-10 Yokai schema æ“´å……ç‰ˆ
**åƒç…§æ–‡ä»¶**: `docs/YOKAI_SCHEMA_EXTENDED.md`

---

## ğŸ“‘ ç›®éŒ„

- [å¬å–šå ´æ™¯æª¢æ¸¬](#å¬å–šå ´æ™¯æª¢æ¸¬)
- [å‹•ä½œåºåˆ—æå–](#å‹•ä½œåºåˆ—æå–)
- [ç‰¹æ•ˆçµ„ç¹”å™¨](#ç‰¹æ•ˆçµ„ç¹”å™¨)
- [é¢¨æ ¼åˆ†é¡å™¨](#é¢¨æ ¼åˆ†é¡å™¨)
- [å¤šæ¦‚å¿µæº–å‚™å™¨](#å¤šæ¦‚å¿µæº–å‚™å™¨)
- [ControlNet ç®¡é“](#controlnet-ç®¡é“)
- [æ•´åˆç®¡é“](#æ•´åˆç®¡é“)

---

## å¬å–šå ´æ™¯æª¢æ¸¬

### yokai_summon_scene_detector.py

æª¢æ¸¬è¯éº—çš„å¦–æ€ªå¬å–šå ´æ™¯ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
python3 scripts/tools/yokai_summon_scene_detector.py \
    <episodes_dir> \
    --output-dir <output_dir>
```

#### å®Œæ•´åƒæ•¸

| åƒæ•¸ | é¡å‹ | é è¨­å€¼ | èªªæ˜ |
|------|------|--------|------|
| `episodes_dir` | ä½ç½®åƒæ•¸ | - | å½±ç‰‡æª”æ¡ˆç›®éŒ„ |
| `--output-dir` | Path | required | è¼¸å‡ºç›®éŒ„ |
| `--extract-mode` | str | `sample` | æå–æ¨¡å¼: `key`/`all`/`sample` |
| `--min-score` | float | `60.0` | æœ€ä½å ´æ™¯è©•åˆ† (0-100) |
| `--device` | str | `cuda` | è™•ç†è¨­å‚™: `cuda`/`cpu` |
| `--batch-size` | int | `8` | æ‰¹æ¬¡å¤§å° |
| `--no-audio` | flag | - | ç¦ç”¨éŸ³è¨Šåˆ†æ |

#### æå–æ¨¡å¼

- **key**: åªæå–é—œéµå¹€ï¼ˆæœ€å°‘åœ–ç‰‡ï¼Œæœ€é«˜å“è³ªï¼‰
- **sample**: æ¡æ¨£æå–ï¼Œæ¯ N å¹€æå–ä¸€å¹€ï¼ˆå¹³è¡¡ï¼‰
- **all**: æå–æ‰€æœ‰å¹€ï¼ˆæœ€å¤šåœ–ç‰‡ï¼‰

#### è©•åˆ†ç¯„åœ

- **60-70**: ä¸€èˆ¬å¬å–šå ´æ™¯
- **70-85**: è¯éº—å¬å–šå ´æ™¯
- **85-100**: è¶…è¯éº—å¬å–šå ´æ™¯

#### è¼¸å‡ºçµæ§‹

```
output_dir/
â”œâ”€â”€ S1.01/
â”‚   â”œâ”€â”€ scene_001234/
â”‚   â”‚   â”œâ”€â”€ scene_001234_frame_001240.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ scene_002456/
â””â”€â”€ summon_scenes_metadata.json
```

#### ç¯„ä¾‹

```bash
# æª¢æ¸¬é«˜å“è³ªå¬å–šå ´æ™¯ï¼ˆåªæå–é—œéµå¹€ï¼‰
python3 scripts/tools/yokai_summon_scene_detector.py \
    /home/b0979/yokai_input_fast \
    --output-dir summon_scenes_high_quality \
    --extract-mode key \
    --min-score 75.0

# å¿«é€Ÿæª¢æ¸¬ï¼ˆæ¡æ¨£æ¨¡å¼ï¼Œè¼ƒä½é–€æª»ï¼‰
python3 scripts/tools/yokai_summon_scene_detector.py \
    /home/b0979/yokai_input_fast \
    --output-dir summon_scenes_all \
    --extract-mode sample \
    --min-score 50.0 \
    --batch-size 16

# CPU æ¨¡å¼ï¼ˆç„¡ GPUï¼‰
python3 scripts/tools/yokai_summon_scene_detector.py \
    /home/b0979/yokai_input_fast \
    --output-dir summon_scenes \
    --device cpu \
    --no-audio
```

---

## å‹•ä½œåºåˆ—æå–

### action_sequence_extractor.py

æå–é€£çºŒå‹•ä½œåºåˆ—ç”¨æ–¼ AnimateDiff motion LoRAã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
python3 scripts/tools/action_sequence_extractor.py \
    <episodes_dir> \
    --output-dir <output_dir> \
    --lengths 16 32
```

#### å®Œæ•´åƒæ•¸

| åƒæ•¸ | é¡å‹ | é è¨­å€¼ | èªªæ˜ |
|------|------|--------|------|
| `episodes_dir` | ä½ç½®åƒæ•¸ | - | å½±ç‰‡æª”æ¡ˆç›®éŒ„ |
| `--output-dir` | Path | required | è¼¸å‡ºç›®éŒ„ |
| `--lengths` | int[] | `[16]` | åºåˆ—é•·åº¦ï¼ˆå¯å¤šå€‹ï¼‰: 8/16/32/64 |
| `--format` | str | `animatediff` | è¼¸å‡ºæ ¼å¼: `animatediff`/`standard` |
| `--min-motion` | float | `2.0` | æœ€å°é‹å‹•å¼·åº¦ |
| `--max-motion` | float | `50.0` | æœ€å¤§é‹å‹•å¼·åº¦ |
| `--min-consistency` | float | `0.85` | æœ€å°å ´æ™¯ä¸€è‡´æ€§ (0-1) |
| `--device` | str | `cuda` | è™•ç†è¨­å‚™ |

#### åºåˆ—é•·åº¦

- **8**: è¶…çŸ­å‹•ä½œï¼ˆå¿«é€Ÿå‹•ä½œï¼‰
- **16**: çŸ­å‹•ä½œï¼ˆå‡ºå ´ã€è½‰èº«ï¼‰â­ æ¨è–¦
- **32**: ä¸­ç­‰å‹•ä½œï¼ˆæ”»æ“Šã€ç§»å‹•ï¼‰
- **64**: é•·å‹•ä½œï¼ˆå®Œæ•´å¬å–šåºåˆ—ï¼‰

#### è¼¸å‡ºæ ¼å¼

- **animatediff**: `0000.png, 0001.png, ...`ï¼ˆAnimateDiff æ¨™æº–ï¼‰
- **standard**: `frame_0000.png, frame_0001.png, ...`

#### è¼¸å‡ºçµæ§‹

```
output_dir/
â”œâ”€â”€ S1.01_seq001234_len16_entrance/
â”‚   â”œâ”€â”€ 0000.png
â”‚   â”œâ”€â”€ 0001.png
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ 0015.png
â”‚   â””â”€â”€ metadata.json
â””â”€â”€ sequences_metadata.json
```

#### ç¯„ä¾‹

```bash
# æå–å¤šç¨®é•·åº¦åºåˆ—
python3 scripts/tools/action_sequence_extractor.py \
    /home/b0979/yokai_input_fast \
    --output-dir motion_sequences \
    --lengths 16 32 64 \
    --format animatediff

# åªæå–é«˜é‹å‹•å ´æ™¯
python3 scripts/tools/action_sequence_extractor.py \
    /home/b0979/yokai_input_fast \
    --output-dir high_motion_sequences \
    --lengths 16 \
    --min-motion 10.0 \
    --max-motion 40.0

# åš´æ ¼å ´æ™¯ä¸€è‡´æ€§
python3 scripts/tools/action_sequence_extractor.py \
    /home/b0979/yokai_input_fast \
    --output-dir consistent_sequences \
    --lengths 32 \
    --min-consistency 0.95
```

---

## ç‰¹æ•ˆçµ„ç¹”å™¨

### special_effects_organizer.py

åˆ†é¡å’Œçµ„ç¹”ç‰¹æ•ˆå ´æ™¯ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
python3 scripts/tools/special_effects_organizer.py \
    <input_dir> \
    --output-dir <output_dir>
```

#### å®Œæ•´åƒæ•¸

| åƒæ•¸ | é¡å‹ | é è¨­å€¼ | èªªæ˜ |
|------|------|--------|------|
| `input_dir` | ä½ç½®åƒæ•¸ | - | è¼¸å…¥ç›®éŒ„ï¼ˆå¦‚å¬å–šå ´æ™¯ï¼‰ |
| `--output-dir` | Path | required | è¼¸å‡ºç›®éŒ„ |
| `--separate-layers` | flag | - | åˆ†é›¢ç‰¹æ•ˆå’Œè§’è‰²å±¤ |
| `--intensity-threshold` | float | `0.3` | ç‰¹æ•ˆå¼·åº¦é–€æª» (0-1) |
| `--device` | str | `cuda` | è™•ç†è¨­å‚™ |

#### è¼¸å‡ºçµæ§‹

```
output_dir/
â”œâ”€â”€ by_type/
â”‚   â”œâ”€â”€ summon/           # å¬å–šç‰¹æ•ˆ
â”‚   â”œâ”€â”€ attack/           # æ”»æ“Šç‰¹æ•ˆ
â”‚   â”œâ”€â”€ magic_circle/     # é­”æ³•é™£
â”‚   â”œâ”€â”€ transformation/   # è®Šèº«ç‰¹æ•ˆ
â”‚   â””â”€â”€ ambient/          # ç’°å¢ƒç‰¹æ•ˆ
â”œâ”€â”€ pure_effects/         # ç´”ç‰¹æ•ˆï¼ˆç§»é™¤è§’è‰²ï¼‰
â”‚   â”œâ”€â”€ summon/
â”‚   â””â”€â”€ ...
â””â”€â”€ combined/             # ç‰¹æ•ˆ+è§’è‰²
```

#### ç‰¹æ•ˆé¡å‹

- **summon**: å¬å–šå‹•ç•«
- **attack**: æ”»æ“Šç‰¹æ•ˆ
- **transformation**: è®Šèº«/é€²åŒ–
- **magic_circle**: é­”æ³•é™£
- **ambient**: ç’°å¢ƒå…‰æ•ˆ

#### ç¯„ä¾‹

```bash
# åŸºæœ¬çµ„ç¹”
python3 scripts/tools/special_effects_organizer.py \
    summon_scenes \
    --output-dir organized_effects

# åˆ†é›¢ç‰¹æ•ˆå±¤ï¼ˆç”¨æ–¼ç´”ç‰¹æ•ˆè¨“ç·´ï¼‰
python3 scripts/tools/special_effects_organizer.py \
    summon_scenes \
    --output-dir organized_effects \
    --separate-layers

# åªä¿ç•™é«˜å¼·åº¦ç‰¹æ•ˆ
python3 scripts/tools/special_effects_organizer.py \
    summon_scenes \
    --output-dir high_intensity_effects \
    --intensity-threshold 0.6 \
    --separate-layers
```

---

## é¢¨æ ¼åˆ†é¡å™¨

### yokai_style_classifier.py

ä½¿ç”¨ AI è‡ªå‹•åˆ†é¡å¦–æ€ªé¢¨æ ¼å’Œå±¬æ€§ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
python3 scripts/tools/yokai_style_classifier.py \
    <clusters_dir> \
    --output-json <taxonomy.json>
```

#### å®Œæ•´åƒæ•¸

| åƒæ•¸ | é¡å‹ | é è¨­å€¼ | èªªæ˜ |
|------|------|--------|------|
| `clusters_dir` | ä½ç½®åƒæ•¸ | - | è§’è‰²èšé¡ç›®éŒ„ |
| `--output-json` | Path | required | è¼¸å‡ºåˆ†é¡æ–‡ä»¶ |
| `--threshold` | float | `0.3` | åˆ†é¡ä¿¡å¿ƒé–€æª» (0-1) |
| `--sample-size` | int | `10` | æ¯å€‹èšé¡æ¡æ¨£åœ–ç‰‡æ•¸ |
| `--no-interactive` | flag | - | ç¦ç”¨äº’å‹•å¯©æ ¸ |
| `--device` | str | `cuda` | è™•ç†è¨­å‚™ |

#### åˆ†é¡ç¶­åº¦

1. **appearance** (å¤–è§€):
   - animal_cat, animal_dog, animal_bird, animal_dragon
   - object_food, object_tool, object_toy
   - humanoid, ghost, abstract

2. **attribute** (å±¬æ€§):
   - fire, water, wind, thunder, earth, ice, light, dark, nature

3. **style** (é¢¨æ ¼):
   - cute, cool, brave, scary, funny, mysterious, elegant

4. **body_type** (é«”å‹):
   - quadruped, bipedal, flying, floating, multi_limbed

#### äº’å‹•æ¨¡å¼

```
[1/128] cluster_000
AI Classification:
  appearance:
    - animal_cat: 0.85
  attribute:
    - fire: 0.68
  style:
    - cute: 0.91

Action (a/m/s/q):
  a - Accept        æ¥å— AI åˆ†é¡
  m - Modify        ä¿®æ”¹åˆ†é¡
  s - Skip          è·³éæ­¤èšé¡
  q - Quit          é€€å‡ºå¯©æ ¸
```

#### ç¯„ä¾‹

```bash
# è‡ªå‹•åˆ†é¡ + äº’å‹•å¯©æ ¸ï¼ˆæ¨è–¦ï¼‰
python3 scripts/tools/yokai_style_classifier.py \
    character_clusters \
    --output-json yokai_taxonomy.json \
    --threshold 0.3 \
    --sample-size 10

# ç´”è‡ªå‹•ï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰
python3 scripts/tools/yokai_style_classifier.py \
    character_clusters \
    --output-json yokai_taxonomy.json \
    --no-interactive

# åš´æ ¼åˆ†é¡ï¼ˆé«˜ä¿¡å¿ƒé–€æª»ï¼‰
python3 scripts/tools/yokai_style_classifier.py \
    character_clusters \
    --output-json yokai_taxonomy_strict.json \
    --threshold 0.5 \
    --sample-size 15

# CPU æ¨¡å¼
python3 scripts/tools/yokai_style_classifier.py \
    character_clusters \
    --output-json yokai_taxonomy.json \
    --device cpu \
    --no-interactive
```

---

## å¤šæ¦‚å¿µæº–å‚™å™¨

### multi_concept_lora_preparer.py

æº–å‚™é¢¨æ ¼çµ„åˆè¨“ç·´ï¼ˆå¦‚ã€Œæ‰€æœ‰è²“å‹å¦–æ€ªã€ï¼‰ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
python3 scripts/tools/multi_concept_lora_preparer.py \
    <clusters_dir> \
    --taxonomy <taxonomy.json> \
    --output-dir <output_dir> \
    --groups <groups.json>
```

#### å®Œæ•´åƒæ•¸

| åƒæ•¸ | é¡å‹ | é è¨­å€¼ | èªªæ˜ |
|------|------|--------|------|
| `clusters_dir` | ä½ç½®åƒæ•¸ | - | è§’è‰²èšé¡ç›®éŒ„ |
| `--taxonomy` | Path | required | é¢¨æ ¼åˆ†é¡æ–‡ä»¶ |
| `--output-dir` | Path | required | è¼¸å‡ºç›®éŒ„ |
| `--groups` | Path | required | çµ„å®šç¾©æ–‡ä»¶ |
| `--training-type` | str | `concept` | è¨“ç·´é¡å‹: `concept`/`style` |
| `--target-samples` | int | `40` | ç›®æ¨™æ¨£æœ¬æ•¸/è§’è‰² |
| `--max-samples` | int | `80` | æœ€å¤§æ¨£æœ¬æ•¸/è§’è‰² |
| `--hierarchical` | flag | - | ä½¿ç”¨éšå±¤è§¸ç™¼è© |
| `--device` | str | `cuda` | è™•ç†è¨­å‚™ |

#### çµ„å®šç¾©æ ¼å¼ (groups.json)

```json
[
  {
    "name": "cat_type_yokai",
    "category": "appearance",
    "values": ["animal_cat"]
  },
  {
    "name": "cute_yokai",
    "category": "style",
    "values": ["cute"]
  },
  {
    "name": "fire_attribute",
    "category": "attribute",
    "values": ["fire"]
  },
  {
    "name": "cute_cat_fire",
    "category": "multi",
    "filters": {
      "appearance": ["animal_cat"],
      "style": ["cute"],
      "attribute": ["fire"]
    }
  }
]
```

#### è¨“ç·´é¡å‹

- **concept**: å­¸ç¿’å¤šå€‹è§’è‰²çš„å…±åŒæ¦‚å¿µ
  - é«˜ç¶­åº¦ï¼ˆä¿ç•™å€‹é«”ç‰¹å¾µï¼‰
  - éšå±¤è§¸ç™¼è©

- **style**: ç´”é¢¨æ ¼å­¸ç¿’
  - ä½ç¶­åº¦ï¼ˆèšç„¦å…±åŒé¢¨æ ¼ï¼‰
  - æ›´é«˜å­¸ç¿’ç‡

#### è§¸ç™¼è©ç³»çµ±

**éšå±¤å¼**ï¼ˆæ¨è–¦ï¼‰:
```
"yokai, cat-type, char000"
Level 1: yokai
Level 2: yokai, cat-type
Level 3: yokai, cat-type, char000
```

**æ‰å¹³å¼**:
```
"cat_type_yokai_char000"
```

#### è¼¸å‡ºçµæ§‹

```
output_dir/
â”œâ”€â”€ cat_type_yokai/
â”‚   â”œâ”€â”€ 12_cat_type_yokai/
â”‚   â”‚   â”œâ”€â”€ cluster_000_img001.png
â”‚   â”‚   â”œâ”€â”€ cluster_000_img001.txt   # "yokai, cat-type, char000, ..."
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ validation/
â”‚   â””â”€â”€ configs/
â”‚       â””â”€â”€ cat_type_yokai_config.toml
â””â”€â”€ multi_concept_metadata.json
```

#### ç¯„ä¾‹

```bash
# åŸºæœ¬å¤šæ¦‚å¿µæº–å‚™
python3 scripts/tools/multi_concept_lora_preparer.py \
    character_clusters \
    --taxonomy yokai_taxonomy.json \
    --output-dir multi_concept_training \
    --groups groups.json \
    --training-type concept

# é¢¨æ ¼è¨“ç·´ï¼ˆèšç„¦å…±åŒç‰¹å¾µï¼‰
python3 scripts/tools/multi_concept_lora_preparer.py \
    character_clusters \
    --taxonomy yokai_taxonomy.json \
    --output-dir style_training \
    --groups style_groups.json \
    --training-type style

# è‡ªå®šç¾©æ¨£æœ¬æ•¸
python3 scripts/tools/multi_concept_lora_preparer.py \
    character_clusters \
    --taxonomy yokai_taxonomy.json \
    --output-dir balanced_training \
    --groups groups.json \
    --target-samples 50 \
    --max-samples 100

# ä½¿ç”¨æ‰å¹³è§¸ç™¼è©
python3 scripts/tools/multi_concept_lora_preparer.py \
    character_clusters \
    --taxonomy yokai_taxonomy.json \
    --output-dir flat_trigger_training \
    --groups groups.json
    # ä¸åŠ  --hierarchical
```

---

## ControlNet ç®¡é“

### controlnet_complete_pipeline.py

ä¸€æ¬¡ç”Ÿæˆæ‰€æœ‰ ControlNet æ§åˆ¶åœ–ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
python3 scripts/tools/controlnet_complete_pipeline.py \
    <input_dir> \
    --output-dir <output_dir>
```

#### å®Œæ•´åƒæ•¸

| åƒæ•¸ | é¡å‹ | é è¨­å€¼ | èªªæ˜ |
|------|------|--------|------|
| `input_dir` | ä½ç½®åƒæ•¸ | - | è¼¸å…¥åœ–ç‰‡ç›®éŒ„ |
| `--output-dir` | Path | required | è¼¸å‡ºç›®éŒ„ |
| `--control-types` | str[] | all | æ§åˆ¶é¡å‹ï¼ˆå¯å¤šå€‹ï¼‰ |
| `--background-dir` | Path | - | èƒŒæ™¯ç›®éŒ„ï¼ˆæ”¹å–„æ·±åº¦åœ–ï¼‰ |
| `--device` | str | `cuda` | è™•ç†è¨­å‚™ |

#### æ§åˆ¶é¡å‹

- **canny**: Canny é‚Šç·£æª¢æ¸¬
- **depth**: æ·±åº¦åœ–ç”Ÿæˆ
- **openpose**: OpenPose å§¿æ…‹æª¢æ¸¬
- **lineart**: ç·šç¨¿æå–
- **segmentation**: åˆ†å‰²é®ç½©

#### è¼¸å‡ºçµæ§‹

```
output_dir/
â”œâ”€â”€ source/              # åŸåœ–
â”œâ”€â”€ canny/               # Canny é‚Šç·£
â”œâ”€â”€ depth/               # æ·±åº¦åœ–
â”œâ”€â”€ openpose/            # å§¿æ…‹éª¨æ¶
â”œâ”€â”€ lineart/             # ç·šç¨¿
â”œâ”€â”€ segmentation/        # åˆ†å‰²é®ç½©
â”œâ”€â”€ captions/            # Caption æ–‡å­—
â””â”€â”€ controlnet_metadata.json
```

#### ç¯„ä¾‹

```bash
# ç”Ÿæˆæ‰€æœ‰é¡å‹
python3 scripts/tools/controlnet_complete_pipeline.py \
    character_clusters/cluster_000 \
    --output-dir controlnet_all

# åªç”Ÿæˆç‰¹å®šé¡å‹
python3 scripts/tools/controlnet_complete_pipeline.py \
    character_clusters/cluster_000 \
    --output-dir controlnet_pose_depth \
    --control-types openpose depth

# ä½¿ç”¨èƒŒæ™¯å±¤æ”¹å–„æ·±åº¦
python3 scripts/tools/controlnet_complete_pipeline.py \
    character_clusters/cluster_000 \
    --output-dir controlnet_with_bg \
    --control-types depth \
    --background-dir layered_frames/background

# æ‰¹æ¬¡è™•ç†æ‰€æœ‰èšé¡
for cluster in character_clusters/cluster_*; do
    cluster_name=$(basename "$cluster")
    python3 scripts/tools/controlnet_complete_pipeline.py \
        "$cluster" \
        --output-dir "controlnet_datasets/$cluster_name" \
        --control-types canny depth openpose
done
```

---

## æ•´åˆç®¡é“

### yokai_advanced_training_pipeline.sh

æ•´åˆæ‰€æœ‰é€²éšåŠŸèƒ½çš„å®Œæ•´ç®¡é“ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
./scripts/batch/yokai_advanced_training_pipeline.sh
```

#### ç’°å¢ƒè®Šæ•¸é…ç½®

```bash
# è¼¸å…¥ç›®éŒ„
export EPISODES_DIR="/home/b0979/yokai_input_fast"
export CHARACTER_CLUSTERS_DIR="/path/to/character_clusters"
export LAYERED_FRAMES_DIR="/path/to/layered_frames"

# è¼¸å‡ºç›®éŒ„
export OUTPUT_BASE="/path/to/advanced_output"

# åŠŸèƒ½é–‹é—œ
export ENABLE_SUMMON_DETECTION="true"
export ENABLE_ACTION_SEQUENCES="true"
export ENABLE_EFFECTS_ORGANIZATION="true"
export ENABLE_STYLE_CLASSIFICATION="true"
export ENABLE_MULTI_CONCEPT="true"
export ENABLE_CONTROLNET="true"

# è™•ç†åƒæ•¸
export SUMMON_MIN_SCORE="60.0"
export SUMMON_EXTRACT_MODE="sample"
export ACTION_LENGTHS="16 32"
export STYLE_THRESHOLD="0.3"
export STYLE_INTERACTIVE="true"
export CONTROLNET_TYPES="canny depth openpose"

# è¨­å‚™
export DEVICE="cuda"
export CONDA_ENV="blip2-env"

# é‹è¡Œç®¡é“
./scripts/batch/yokai_advanced_training_pipeline.sh
```

#### è™•ç†éšæ®µ

1. **éšæ®µ 1**: å¬å–šå ´æ™¯æª¢æ¸¬
2. **éšæ®µ 2**: å‹•ä½œåºåˆ—æå–
3. **éšæ®µ 3**: ç‰¹æ•ˆçµ„ç¹”
4. **éšæ®µ 4**: é¢¨æ ¼åˆ†é¡
5. **éšæ®µ 5**: å¤šæ¦‚å¿µæº–å‚™
6. **éšæ®µ 6**: ControlNet é è™•ç†

#### è¼¸å‡ºçµæ§‹

```
OUTPUT_BASE/
â”œâ”€â”€ summon_scenes/
â”œâ”€â”€ action_sequences/
â”œâ”€â”€ organized_effects/
â”œâ”€â”€ yokai_taxonomy.json
â”œâ”€â”€ concept_groups.json
â”œâ”€â”€ multi_concept_training/
â”œâ”€â”€ controlnet_datasets/
â””â”€â”€ pipeline_summary.txt
```

#### ç¯„ä¾‹

```bash
# é‹è¡Œæ‰€æœ‰éšæ®µ
./scripts/batch/yokai_advanced_training_pipeline.sh

# åªé‹è¡Œç‰¹å®šéšæ®µ
export ENABLE_SUMMON_DETECTION="true"
export ENABLE_ACTION_SEQUENCES="false"
export ENABLE_EFFECTS_ORGANIZATION="false"
export ENABLE_STYLE_CLASSIFICATION="false"
export ENABLE_MULTI_CONCEPT="false"
export ENABLE_CONTROLNET="false"
./scripts/batch/yokai_advanced_training_pipeline.sh

# é«˜å“è³ªæ¨¡å¼
export SUMMON_MIN_SCORE="75.0"
export SUMMON_EXTRACT_MODE="key"
export STYLE_THRESHOLD="0.4"
export STYLE_SAMPLE_SIZE="15"
./scripts/batch/yokai_advanced_training_pipeline.sh

# å¿«é€Ÿæ¨¡å¼
export SUMMON_MIN_SCORE="50.0"
export SUMMON_EXTRACT_MODE="sample"
export ACTION_LENGTHS="16"
export STYLE_INTERACTIVE="false"
export CONTROLNET_TYPES="canny depth"
./scripts/batch/yokai_advanced_training_pipeline.sh
```

---

## ğŸ”— å·¥ä½œæµç¨‹æ•´åˆ

### å·¥ä½œæµç¨‹ 1: å¬å–šç‰¹æ•ˆ LoRA

```bash
# 1. æª¢æ¸¬
python3 scripts/tools/yokai_summon_scene_detector.py \
    /home/b0979/yokai_input_fast \
    --output-dir summon_scenes \
    --extract-mode sample

# 2. çµ„ç¹”
python3 scripts/tools/special_effects_organizer.py \
    summon_scenes \
    --output-dir organized_effects \
    --separate-layers

# 3. Caption + æº–å‚™ï¼ˆä½¿ç”¨ç¾æœ‰å·¥å…·ï¼‰
python3 scripts/tools/batch_generate_captions_yokai.py organized_effects/by_type/summon
python3 scripts/tools/prepare_yokai_lora_training.py organized_effects/by_type/summon \
    --output-dir training_data/summon_effects

# 4. è¨“ç·´
accelerate launch train_network.py \
    --config_file training_data/summon_effects/configs/summon_effects_config.toml
```

### å·¥ä½œæµç¨‹ 2: é¢¨æ ¼çµ„åˆ LoRA

```bash
# 1. åˆ†é¡
python3 scripts/tools/yokai_style_classifier.py \
    character_clusters \
    --output-json yokai_taxonomy.json

# 2. å®šç¾©çµ„
cat > cat_group.json <<EOF
[{"name": "cat_type_yokai", "category": "appearance", "values": ["animal_cat"]}]
EOF

# 3. æº–å‚™
python3 scripts/tools/multi_concept_lora_preparer.py \
    character_clusters \
    --taxonomy yokai_taxonomy.json \
    --output-dir cat_lora_training \
    --groups cat_group.json

# 4. è¨“ç·´
accelerate launch train_network.py \
    --config_file cat_lora_training/cat_type_yokai/configs/cat_type_yokai_config.toml
```

### å·¥ä½œæµç¨‹ 3: å®Œæ•´ç®¡é“

```bash
# ä¸€æ¬¡é‹è¡Œæ‰€æœ‰éšæ®µ
./scripts/batch/yokai_advanced_training_pipeline.sh

# æŸ¥çœ‹ç¸½çµ
cat /path/to/advanced_output/pipeline_summary.txt
```

---

## ğŸ› ï¸ å¸¸ç”¨åƒæ•¸çµ„åˆ

### é«˜å“è³ªè¨­å®š

```bash
--min-score 75.0
--extract-mode key
--threshold 0.4
--sample-size 15
--target-samples 50
```

### å¹³è¡¡è¨­å®šï¼ˆæ¨è–¦ï¼‰

```bash
--min-score 60.0
--extract-mode sample
--threshold 0.3
--sample-size 10
--target-samples 40
```

### å¿«é€Ÿæ¸¬è©¦è¨­å®š

```bash
--min-score 50.0
--extract-mode sample
--threshold 0.2
--sample-size 5
--target-samples 20
--no-interactive
```

### ä½è³‡æºè¨­å®š

```bash
--device cpu
--batch-size 4
--sample-size 5
--no-audio
```

---

## ğŸ“Š è¼¸å‡ºæ–‡ä»¶åƒè€ƒ

### summon_scenes_metadata.json

```json
{
  "total_scenes": 45,
  "episodes_processed": 12,
  "scenes": [
    {
      "scene_id": "scene_001234",
      "episode": "S1.01",
      "start_frame": 1234,
      "end_frame": 1256,
      "score": 85.5,
      "effects": {
        "has_flash": true,
        "has_magic_circle": true,
        "num_circles": 2,
        "radial_score": 0.8
      }
    }
  ]
}
```

### yokai_taxonomy.json

```json
{
  "total_clusters": 128,
  "clusters": [
    {
      "cluster_name": "cluster_000",
      "num_samples": 10,
      "classifications": {
        "appearance": {"animal_cat": 0.85},
        "attribute": {"fire": 0.68},
        "style": {"cute": 0.91},
        "body_type": {"quadruped": 0.72}
      }
    }
  ],
  "statistics": {
    "by_appearance": {"animal_cat": 15, "humanoid": 8},
    "by_attribute": {"fire": 12, "water": 10}
  }
}
```

### multi_concept_metadata.json

```json
{
  "groups": [
    {
      "name": "cat_type_yokai",
      "num_clusters": 15,
      "total_samples": 600,
      "trigger_words": "yokai, cat-type",
      "training_params": {
        "network_dim": 48,
        "network_alpha": 24,
        "max_train_epochs": 18
      }
    }
  ]
}
```

---

## ğŸ” æ•…éšœæ’é™¤

### è¨˜æ†¶é«”ä¸è¶³

```bash
--device cpu                    # ä½¿ç”¨ CPU
--batch-size 4                  # æ¸›å°‘æ‰¹æ¬¡
--sample-size 5                 # æ¸›å°‘æ¨£æœ¬
```

### CLIP æ¨¡å‹åŠ è¼‰å¤±æ•—

```bash
# æª¢æŸ¥ç¶²çµ¡é€£æ¥
# æ¨¡å‹æœƒè‡ªå‹•ä¸‹è¼‰åˆ° ~/.cache/huggingface/

# æˆ–æ‰‹å‹•ä¸‹è¼‰
huggingface-cli download openai/clip-vit-base-patch32
```

### éŸ³è¨Šè™•ç†å¤±æ•—

```bash
# å®‰è£ä¾è³´
pip install librosa soundfile

# æˆ–ç¦ç”¨éŸ³è¨Š
--no-audio
```

### äº’å‹•æ¨¡å¼ç„¡æ³•ä½¿ç”¨

```bash
# æ‰¹æ¬¡æ¨¡å¼
--no-interactive
```

---

## ğŸ“š ç›¸é—œæ–‡æª”

- **ä½¿ç”¨æŒ‡å—**: `USAGE_GUIDE.md` - åŸºç¤è¨“ç·´æµç¨‹
- **å·¥å…·åƒè€ƒ**: `TOOLS_QUICK_REFERENCE.md` - åŸºç¤å·¥å…·åƒè€ƒ
- **é€²éšå¿«é€Ÿé–‹å§‹**: `ADVANCED_FEATURES_QUICK_START.md` - é€²éšåŠŸèƒ½å¿«é€Ÿé–‹å§‹
- **é€²éšè¨“ç·´æŒ‡å—**: `YOKAI_ADVANCED_TRAINING_GUIDE.md` - å®Œæ•´è¨“ç·´æ•™ç¨‹
- **å·¥å…·è¦æ ¼**: `ADVANCED_TOOLS_SPECIFICATION.md` - è©³ç´°è¦æ ¼æ–‡æª”

---

**æœ€å¾Œæ›´æ–°**: 2025-10-30
**ç‰ˆæœ¬**: v1.0
**ç‹€æ…‹**: 6/13 æ ¸å¿ƒå·¥å…·å·²å¯¦ä½œä¸¦æ–‡æª”åŒ–
